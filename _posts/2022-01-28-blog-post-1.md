---
layout: post
title: Blog Post 1
---

In this blog post I will explore climate data from the National Oceanic and Atmospheric Administration (NOAA). I will then create interactive visualizations from this data.

The packages that I will be using today.
```python
from matplotlib import pyplot as plt
import numpy as np
import pandas as pd
import sqlite3
from plotly import express as px
from sklearn.linear_model import LinearRegression
import calendar
```

## Getting and cleaning data from 'temps.csv'

First I create my database file, which I'll calls "temps.db" and create a connection to it, all in one line of code.
```python
conn = sqlite3.connect("temps.db") #a sqlite3 connection object
```

I want to preview my data, which I have in "temps.csv", but loading that into a pandas dataframe is slow and inefficient if I just want a peek. Therefore, I'll create a dataframe iterator with a smaller 'chunksize' to just grab a managable piece of the data. This'll also be useful when filling our database with this csv.
```python
df_iter = pd.read_csv("temps.csv", chunksize = 100000)
df = df_iter.__next__()
df.head()
```
![1raw.png](\images\1raw.png)

I can see this is 'wide' data, but it would be easier to work with as 'tall' data. This process involves using set_index() on the columns I don't wish to enlongate. Then using stack() and reset_index() for the 'wide' $$\rightarrow$$ 'tall' conversion.
```python
def prepare_df(df):
    """
    Given a dataframe in the structure of "temps.csv", widen the data 
    on its months and clean the column names. Also convert the 
    hundredths of degrees to degrees for temperature. Return the 
    widened dataframe.
    """
    df = df.set_index(keys=["ID", "Year"]) #the columns not to widen
    df = df.stack()
    df = df.reset_index()
    df = df.rename(columns = {"level_2"  : "Month" , 0 : "Temp"}) 
    #found what the previous column names were after testing
    df["Month"] = df["Month"].str[5:].astype(int) 
    #extract the text after 'VALUE' which is a number corresponding to the month
    df["Temp"]  = df["Temp"] / 100
    return(df)
```
I wrap this in a function along with other things to clean the data, like making good column names, getting the month as an int, and converting the tempuratures to everyday values.

With this function and the dataframe iterator from before, I can efficiently read my csv into my database file. 
```python
df_iter = pd.read_csv("temps.csv", chunksize = 100000)
for df in df_iter:
    df = prepare_df(df)
    df.to_sql("temperatures", conn, if_exists = "append", index = False)
```

Here's what the cleaned data looks like.
```python
df.head()
```
![2prepared.png](\images\2prepared.png)

## Getting data about NOAA climate stations and country codes
The next steps involve grabbing csv's from the internet, reading them into pandas dataframes, then adding them to our database

First we gather data on the climate stations of the NOAA:

```python
url = "https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/noaa-ghcn/station-metadata.csv" 
#data from the internet
stations = pd.read_csv(url) 
#don't need dataframe iterators since that data isn't large
stations["FIPS 10-4"] = stations["ID"].str[0:2] 
#adding a column, which is the first two characters of another, which ends up being its country code
#country code will be useful merging later on
stations.to_sql("stations", conn, if_exists = "replace", index = False) 
#adding it to our database as another table
```

```python

```

```python

```

```python

```

```python

```

```python

```

```python

```

```python

```