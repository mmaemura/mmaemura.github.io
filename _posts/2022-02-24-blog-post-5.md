---
layout: post
title: Blog Post 4
---

```python
import tensorflow as tf

```


```python
import os
from tensorflow.keras import utils
```


```python
from tensorflow.keras import models, layers, losses
```


```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```

    Found 2000 files belonging to 2 classes.
    Found 1000 files belonging to 2 classes.
    


```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```


```python
from matplotlib import pyplot as plt

class_names = train_dataset.class_names



fig, ax = plt.subplots(2,3, figsize=(8,6))
i = 0
for images, labels in train_dataset.take(1):
  print(i)
  row = i // 3
  col = i % 3
  if (class_names[labels[i]] == 'cats') and (i < 3):
    ax[row,col].imshow(images[i].numpy().astype("uint8"))
    ax[row,col].set_title(class_names[labels[i]])
  print(f"row: {row}, col: {col}")
  i += 1
  if (class_names[labels[i]] == 'dogs') and (i > 2):
    ax[row,col].imshow(images[i].numpy().astype("uint8"))
    ax[row,col].set_title(class_names[labels[i]])
  print(f"row: {row}, col: {col}")
  i += 1
  if i == 6:
    break
  print(i, class_names[labels[i]])

    
    # for i in range(6):
    #   row = i // 3
    #   col = i % 3

    #   ax[row,col].imshow(cat_images[i][0].numpy().astype("uint8"))
    #   print(class_names[labels[i]])





```


    ---------------------------------------------------------------------------

    AttributeError                            Traceback (most recent call last)

    <ipython-input-12-a7f805c828db> in <module>()
          1 from matplotlib import pyplot as plt
          2 
    ----> 3 class_names = train_dataset.class_names
          4 
          5 
    

    AttributeError: 'PrefetchDataset' object has no attribute 'class_names'



```python
from tensorflow.keras import models, layers, losses

model1 = models.Sequential([
      layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', input_shape = (160,160,3)),
      layers.MaxPooling2D(pool_size = (2,2)),
      layers.Dropout(0.2),
      layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'),
      layers.MaxPooling2D(pool_size = (2,2)),
      layers.Flatten(),
      layers.Dense(64, activation = 'relu'),
      layers.Dense(2)
])
```


```python
model1.compile(loss=losses.SparseCategoricalCrossentropy(from_logits=True),
              optimizer='adam', 
              metrics=['accuracy'])
```


```python
history = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 15s 83ms/step - loss: 88.8956 - accuracy: 0.5060 - val_loss: 0.6991 - val_accuracy: 0.5173
    Epoch 2/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.6962 - accuracy: 0.5095 - val_loss: 0.6954 - val_accuracy: 0.5309
    Epoch 3/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.6852 - accuracy: 0.5550 - val_loss: 0.6934 - val_accuracy: 0.5322
    Epoch 4/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6415 - accuracy: 0.6140 - val_loss: 0.7038 - val_accuracy: 0.5545
    Epoch 5/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.5936 - accuracy: 0.6615 - val_loss: 0.7643 - val_accuracy: 0.5396
    Epoch 6/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.4998 - accuracy: 0.7345 - val_loss: 0.8213 - val_accuracy: 0.5631
    Epoch 7/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.3851 - accuracy: 0.8105 - val_loss: 0.9372 - val_accuracy: 0.5532
    Epoch 8/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.2931 - accuracy: 0.8645 - val_loss: 1.0258 - val_accuracy: 0.5767
    Epoch 9/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.2181 - accuracy: 0.9045 - val_loss: 1.2624 - val_accuracy: 0.5705
    Epoch 10/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.1961 - accuracy: 0.9130 - val_loss: 1.8668 - val_accuracy: 0.5866
    Epoch 11/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.1422 - accuracy: 0.9385 - val_loss: 1.7191 - val_accuracy: 0.5817
    Epoch 12/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.1237 - accuracy: 0.9550 - val_loss: 1.9675 - val_accuracy: 0.5631
    Epoch 13/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.0801 - accuracy: 0.9690 - val_loss: 2.6227 - val_accuracy: 0.5817
    Epoch 14/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.0653 - accuracy: 0.9765 - val_loss: 2.3737 - val_accuracy: 0.6015
    Epoch 15/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.0743 - accuracy: 0.9755 - val_loss: 2.2416 - val_accuracy: 0.6040
    Epoch 16/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.0452 - accuracy: 0.9795 - val_loss: 2.6585 - val_accuracy: 0.5792
    Epoch 17/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.0243 - accuracy: 0.9900 - val_loss: 3.1597 - val_accuracy: 0.5767
    Epoch 18/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 2.8639 - val_accuracy: 0.6002
    Epoch 19/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.0564 - accuracy: 0.9870 - val_loss: 3.1530 - val_accuracy: 0.6002
    Epoch 20/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.0811 - accuracy: 0.9800 - val_loss: 3.3894 - val_accuracy: 0.5668
    


```python
from matplotlib import pyplot as plt
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f822c49fd90>




    
![png](output_9_1.png)
    



```python
train_dataset.take(1)
```




    <TakeDataset element_spec=(TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>




```python
data_augmentation = models.Sequential([
  layers.RandomFlip('horizontal_and_vertical')
])

fig, ax = plt.subplots(1,2)

for images, labels in train_dataset.take(1):
  ax[0].imshow(images[0].numpy().astype("uint8"))
  augmented_image = data_augmentation(images[0].numpy().astype("uint8"))
  ax[1].imshow(augmented_image)
  break
```

    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    


    
![png](output_11_1.png)
    



```python
model2 = models.Sequential([
      layers.RandomFlip(),
      layers.RandomRotation(factor = .5),
      layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', input_shape = (160,160,3)),
      layers.MaxPooling2D(pool_size = (2,2)),
      layers.Dropout(0.2),
      layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'),
      layers.MaxPooling2D(pool_size = (2,2)),
      layers.Flatten(),
      layers.Dense(64, activation = 'relu'),
      layers.Dense(2)
])
```


```python
model2.compile(loss=losses.SparseCategoricalCrossentropy(from_logits=True),
              optimizer='adam', 
              metrics=['accuracy'])
```


```python
history = model2.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 18s 91ms/step - loss: 54.3313 - accuracy: 0.4905 - val_loss: 0.6914 - val_accuracy: 0.5297
    Epoch 2/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6961 - accuracy: 0.5045 - val_loss: 0.6928 - val_accuracy: 0.5149
    Epoch 3/20
    63/63 [==============================] - 6s 98ms/step - loss: 0.6929 - accuracy: 0.5170 - val_loss: 0.6911 - val_accuracy: 0.5136
    Epoch 4/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.6972 - accuracy: 0.4895 - val_loss: 0.6926 - val_accuracy: 0.5124
    Epoch 5/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.6918 - accuracy: 0.5220 - val_loss: 0.6929 - val_accuracy: 0.4777
    Epoch 6/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.6930 - accuracy: 0.5205 - val_loss: 0.6929 - val_accuracy: 0.4864
    Epoch 7/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.6938 - accuracy: 0.5025 - val_loss: 0.6926 - val_accuracy: 0.4975
    Epoch 8/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6901 - accuracy: 0.5375 - val_loss: 0.6936 - val_accuracy: 0.4876
    Epoch 9/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6891 - accuracy: 0.5605 - val_loss: 0.6920 - val_accuracy: 0.4926
    Epoch 10/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6921 - accuracy: 0.5295 - val_loss: 0.6928 - val_accuracy: 0.4802
    Epoch 11/20
    63/63 [==============================] - 6s 91ms/step - loss: 0.6867 - accuracy: 0.5300 - val_loss: 0.6904 - val_accuracy: 0.5408
    Epoch 12/20
    63/63 [==============================] - 6s 90ms/step - loss: 0.6882 - accuracy: 0.5345 - val_loss: 0.6946 - val_accuracy: 0.4950
    Epoch 13/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.6977 - accuracy: 0.5565 - val_loss: 0.6931 - val_accuracy: 0.4851
    Epoch 14/20
    63/63 [==============================] - 6s 92ms/step - loss: 0.6918 - accuracy: 0.5595 - val_loss: 0.6941 - val_accuracy: 0.4988
    Epoch 15/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6883 - accuracy: 0.5385 - val_loss: 0.6938 - val_accuracy: 0.4975
    Epoch 16/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.6895 - accuracy: 0.5310 - val_loss: 0.6931 - val_accuracy: 0.4975
    Epoch 17/20
    63/63 [==============================] - 6s 90ms/step - loss: 0.6860 - accuracy: 0.5650 - val_loss: 0.6924 - val_accuracy: 0.4864
    Epoch 18/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.6850 - accuracy: 0.5640 - val_loss: 0.6898 - val_accuracy: 0.5074
    Epoch 19/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6866 - accuracy: 0.5520 - val_loss: 0.6916 - val_accuracy: 0.5074
    Epoch 20/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6813 - accuracy: 0.5710 - val_loss: 0.6889 - val_accuracy: 0.5186
    


```python

plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f168747fa50>




    
![png](output_15_1.png)
    



```python
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])

model3 = models.Sequential([
      preprocessor,
      layers.RandomFlip(),
      layers.RandomRotation(factor = .5),
      layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', input_shape = (160,160,3)),
      layers.MaxPooling2D(pool_size = (2,2)),
      layers.Dropout(0.2),
      layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'),
      layers.MaxPooling2D(pool_size = (2,2)),
      layers.Flatten(),
      layers.Dense(64, activation = 'relu'),
      layers.Dense(2)
])

model3.compile(loss=losses.SparseCategoricalCrossentropy(from_logits=True),
              optimizer='adam', 
              metrics=['accuracy'])

history = model3.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 7s 86ms/step - loss: 0.9060 - accuracy: 0.5395 - val_loss: 0.6836 - val_accuracy: 0.6052
    Epoch 2/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6645 - accuracy: 0.6055 - val_loss: 0.6547 - val_accuracy: 0.6200
    Epoch 3/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6487 - accuracy: 0.6120 - val_loss: 0.6460 - val_accuracy: 0.6411
    Epoch 4/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6372 - accuracy: 0.6345 - val_loss: 0.6216 - val_accuracy: 0.6411
    Epoch 5/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6230 - accuracy: 0.6475 - val_loss: 0.6142 - val_accuracy: 0.6522
    Epoch 6/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6098 - accuracy: 0.6755 - val_loss: 0.6048 - val_accuracy: 0.6634
    Epoch 7/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.6087 - accuracy: 0.6675 - val_loss: 0.6195 - val_accuracy: 0.6609
    Epoch 8/20
    63/63 [==============================] - 5s 83ms/step - loss: 0.5945 - accuracy: 0.6840 - val_loss: 0.6140 - val_accuracy: 0.6522
    Epoch 9/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.5870 - accuracy: 0.6815 - val_loss: 0.5971 - val_accuracy: 0.6931
    Epoch 10/20
    63/63 [==============================] - 7s 103ms/step - loss: 0.5764 - accuracy: 0.7020 - val_loss: 0.5677 - val_accuracy: 0.7042
    Epoch 11/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.5649 - accuracy: 0.7060 - val_loss: 0.5705 - val_accuracy: 0.7129
    Epoch 12/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.5599 - accuracy: 0.7025 - val_loss: 0.5616 - val_accuracy: 0.7228
    Epoch 13/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.5581 - accuracy: 0.6980 - val_loss: 0.5655 - val_accuracy: 0.7228
    Epoch 14/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.5460 - accuracy: 0.7245 - val_loss: 0.5570 - val_accuracy: 0.7092
    Epoch 15/20
    63/63 [==============================] - 6s 90ms/step - loss: 0.5454 - accuracy: 0.7245 - val_loss: 0.5516 - val_accuracy: 0.7178
    Epoch 16/20
    63/63 [==============================] - 6s 95ms/step - loss: 0.5432 - accuracy: 0.7255 - val_loss: 0.5677 - val_accuracy: 0.6993
    Epoch 17/20
    63/63 [==============================] - 6s 94ms/step - loss: 0.5373 - accuracy: 0.7310 - val_loss: 0.5466 - val_accuracy: 0.7166
    Epoch 18/20
    63/63 [==============================] - 6s 97ms/step - loss: 0.5371 - accuracy: 0.7265 - val_loss: 0.5741 - val_accuracy: 0.6943
    Epoch 19/20
    63/63 [==============================] - 6s 97ms/step - loss: 0.5260 - accuracy: 0.7315 - val_loss: 0.5419 - val_accuracy: 0.7327
    Epoch 20/20
    63/63 [==============================] - 6s 94ms/step - loss: 0.5270 - accuracy: 0.7325 - val_loss: 0.5438 - val_accuracy: 0.7327
    


```python

plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f16886fa850>




    
![png](output_17_1.png)
    



```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```

    Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5
    9412608/9406464 [==============================] - 0s 0us/step
    9420800/9406464 [==============================] - 0s 0us/step
    


```python
model4 = models.Sequential([
      # preprocessor,
      # layers.RandomFlip(),
      # layers.RandomRotation(factor = .5),
      base_model_layer,
      #layers.MaxPooling2D(pool_size = (2,2)),
      layers.Dense(2)
])

model4.compile(loss=losses.SparseCategoricalCrossentropy(from_logits=True),
              optimizer='adam', 
              metrics=['accuracy'])


```


```python
model4.summary()
```

    Model: "sequential_11"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     model_2 (Functional)        (None, 5, 5, 1280)        2257984   
                                                                     
     dense_14 (Dense)            (None, 5, 5, 2)           2562      
                                                                     
    =================================================================
    Total params: 2,260,546
    Trainable params: 2,562
    Non-trainable params: 2,257,984
    _________________________________________________________________
    


```python
history = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    


    ---------------------------------------------------------------------------

    InvalidArgumentError                      Traceback (most recent call last)

    <ipython-input-29-fe8e86b6436e> in <module>()
          1 history = model4.fit(train_dataset, 
          2                      epochs=20,
    ----> 3                      validation_data=validation_dataset)
    

    /usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)
         65     except Exception as e:  # pylint: disable=broad-except
         66       filtered_tb = _process_traceback_frames(e.__traceback__)
    ---> 67       raise e.with_traceback(filtered_tb) from None
         68     finally:
         69       del filtered_tb
    

    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
         53     ctx.ensure_initialized()
         54     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
    ---> 55                                         inputs, attrs, num_outputs)
         56   except core._NotOkStatusException as e:
         57     if name is not None:
    

    InvalidArgumentError: Graph execution error:
    
    Detected at node 'Equal' defined at (most recent call last):
        File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
          "__main__", mod_spec)
        File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
          exec(code, run_globals)
        File "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py", line 16, in <module>
          app.launch_new_instance()
        File "/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py", line 846, in launch_instance
          app.start()
        File "/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py", line 499, in start
          self.io_loop.start()
        File "/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py", line 132, in start
          self.asyncio_loop.run_forever()
        File "/usr/lib/python3.7/asyncio/base_events.py", line 541, in run_forever
          self._run_once()
        File "/usr/lib/python3.7/asyncio/base_events.py", line 1786, in _run_once
          handle._run()
        File "/usr/lib/python3.7/asyncio/events.py", line 88, in _run
          self._context.run(self._callback, *self._args)
        File "/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py", line 122, in _handle_events
          handler_func(fileobj, events)
        File "/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py", line 300, in null_wrapper
          return fn(*args, **kwargs)
        File "/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py", line 452, in _handle_events
          self._handle_recv()
        File "/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py", line 481, in _handle_recv
          self._run_callback(callback, msg)
        File "/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py", line 431, in _run_callback
          callback(*args, **kwargs)
        File "/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py", line 300, in null_wrapper
          return fn(*args, **kwargs)
        File "/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py", line 283, in dispatcher
          return self.dispatch_shell(stream, msg)
        File "/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py", line 233, in dispatch_shell
          handler(stream, idents, msg)
        File "/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py", line 399, in execute_request
          user_expressions, allow_stdin)
        File "/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py", line 208, in do_execute
          res = shell.run_cell(code, store_history=store_history, silent=silent)
        File "/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py", line 537, in run_cell
          return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
        File "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py", line 2718, in run_cell
          interactivity=interactivity, compiler=compiler, result=result)
        File "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py", line 2822, in run_ast_nodes
          if self.run_code(code, result):
        File "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py", line 2882, in run_code
          exec(code_obj, self.user_global_ns, self.user_ns)
        File "<ipython-input-29-fe8e86b6436e>", line 3, in <module>
          validation_data=validation_dataset)
        File "/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py", line 64, in error_handler
          return fn(*args, **kwargs)
        File "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py", line 1384, in fit
          tmp_logs = self.train_function(iterator)
        File "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py", line 1021, in train_function
          return step_function(self, iterator)
        File "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py", line 1010, in step_function
          outputs = model.distribute_strategy.run(run_step, args=(data,))
        File "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py", line 1000, in run_step
          outputs = model.train_step(data)
        File "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py", line 864, in train_step
          return self.compute_metrics(x, y, y_pred, sample_weight)
        File "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py", line 957, in compute_metrics
          self.compiled_metrics.update_state(y, y_pred, sample_weight)
        File "/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py", line 459, in update_state
          metric_obj.update_state(y_t, y_p, sample_weight=mask)
        File "/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py", line 70, in decorated
          update_op = update_state_fn(*args, **kwargs)
        File "/usr/local/lib/python3.7/dist-packages/keras/metrics.py", line 178, in update_state_fn
          return ag_update_state(*args, **kwargs)
        File "/usr/local/lib/python3.7/dist-packages/keras/metrics.py", line 729, in update_state
          matches = ag_fn(y_true, y_pred, **self._fn_kwargs)
        File "/usr/local/lib/python3.7/dist-packages/keras/metrics.py", line 4086, in sparse_categorical_accuracy
          return tf.cast(tf.equal(y_true, y_pred), backend.floatx())
    Node: 'Equal'
    required broadcastable shapes
    	 [[{{node Equal}}]] [Op:__inference_train_function_56444]



```python
for images, labels in train_dataset.take(1):
  print(images.shape)
```

    (32, 160, 160, 3)
    
