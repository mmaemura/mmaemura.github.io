---
layout: post
title: Blog Post 4
---

In this blog post, I will implement a version of the 'spectral clustering' algorithm, used for classification tasks in machine learning.

![spec1.png](/images/spec1.png)

The task is to classify data points that resemble something like those above. Using k-Means, the simplest classification algorithm, we classify them as:

![spec2.png](/images/spec2.png)

However, by human eye, we see the classification should more so resemble this:

put image when done

# Construct a 'Similarity Matrix' A

We want an $$n$$x$$n$$ symmetric matrix A, where entry A[i,j] is 1 if points i and j are 'close' to each other, and 0 if they are not close to each other.

```python
from sklearn import metrics

A = metrics.pairwise_distances(X) #nxn matrix for distances
eps = 0.4
Eps = np.full((n,n), eps) #nxn matrix all with value eps
A = A < Eps #nxn boolean matrix, 1 if within eps, 0 otherwise
A = 1 * A #boolean to int conversion
np.fill_diagonal(A, val = 0) #change diagonal entries 1 to 0
```

Here X holds are data and is a $$n$$x$$2$$ numpy array, where each row is the coordinates of a data point.

pairwise_distances() returns a matrix for the distance between each of the points amoung all the points, resulting in an $$n$$x$$n$$ matrix.

Then we compare the matrix from pairwise_distances() to a threshhold value `eps`

Note: The diagonal entries are initially 1 because they are 0 distance within themselves, however we change them to 0.

Here's the first 10 rows and columns of `A`

```python
print(A[:10,:10])
```
```
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 1 0 0 0 0]
 [0 0 0 0 0 1 0 0 0 0]
 [0 0 0 1 1 0 0 0 0 0]
 [0 0 0 0 0 0 0 1 0 0]
 [0 0 0 0 0 0 1 0 0 0]
 [0 0 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 1 0]]
```

# The 'Binary Norm Cut' metric

We want to create a metric for how good any two clusters are-- we will call this the 'binary norm cut objective'.

This metric will have a nice, small value when:

1. the number of points in one cluster that are close to points in the other cluster is small

2. neither cluster is too small

So we define the binary norm cut objective as:

$$N_A(C_0, C_1) \equiv \operatorname{cut}(C_0, C_1) 
\left( \frac{1}{\operatorname{vol}(C_0)}+\frac{1}{\operatorname{vol}(C_1)} \right)$$

where $$C_0$$ and $$C_1$$ are our two clusters. $$\operatorname{cut}(C_0,C_1)$$ is a measure of the first criteria, and $$\left( \frac{1}{\operatorname{vol}(C_0)}+\frac{1}{\operatorname{vol}(C_1)} \right)$$ is a measure of the second criteria.

## The $$\operatorname{cut}(C_0,C_1)$$ function